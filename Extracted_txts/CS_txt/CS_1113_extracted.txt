Section 1.3.

The History of Artificial Intelligence 23

 

FRAMES.

experts, and considerably better thanjunior doctors. It also contained two major differences from
DENDRAL. First, unlike the DENDRAL mules, no general theoretical model existed from which the
MYCIN rules could be deduced. They had to be acquired from extensive interviewing of experts,
who in turn acquired them from direct experience of cases. Second, the rules had to reflect the
uncertainty associated with medical knowledge. MYCIN incorporated a calculus of uncertainty
called certainty factors (see Chapter 14), which seemed (at the time) to fit well with how doctors
assessed the impact of evidence on the diagnosis.

Other approaches to medical diagnosis were also followed. At Rutgers University, Saul
Amarel’s Computers in Biomedicine project began an ambitious attempt to diagnose diseases
based on explicit knowledge of the causal mechanisms of the disease process. Meanwhile, large
groups at MIT and the New England Medical Center were pursuing an approach to diagnosis and
treatment based on the theories of probability and utility. Their aim was to build systems that
gave provably optimal medical recommendations. In medicine, the Stanford approach using rules
provided by doctors proved more popular at first. But another probabilistic reasoning system,
PROSPECTOR (Duda ef al., 1979), generated enormous publicity by recommending exploratory
drilling at a geological site that proved to contain a large molybdenum deposit.

The importance of domain knowledge was also apparent in the area of understanding
natural language. Although Winograd's SHRDLU system for understanding natural language had
engendered a good deal of excitement, its dependence on syntactic analysis caused some of
the same problems as occured in the early machine translation work. It was able to overcome
ambiguity and understand pronoun references, but this was mainly because it was designed
specifically for one area—the blocks world. Several researchers, including Eugene Charniak,
a fellow graduate student of Winograd's at MIT, suggested that robust language understanding
would require general knowledge about the world and a general method for using that knowledge

At Yale, the linguist-turned-AI-researcherRoger Schank emphasized this point by claiming,
"There is no such thing as syntax," which upset a lot of linguists, but did serve to start a useful
discussion. Schank and his students built a series of programs (Schank and Abelson, 1977;
Schank and Riesbeck, 1981;Dyer, 1983) that all had the task of understanding natural language.
The emphasis, however, was less on language per se and more on the problems of representing
and reasoning with the knowledge required for language understanding. The problems included
representing stereotypical situations (Cullingford, 1981), describing human memory organization
(Rieger, 1976; Kolodner, 1983), and understanding plans and goals (Wilensky, 1983). William
Woods (1973) built the LUNAR system, which allowed geologists to ask questions in English
about the rock samples brought back by the Apollo moon mission. LUNAR was the first natural
language program that was used by people other than the system's author to get real work done.
Since then, many natural language programs have been used as interfaces to databases.

The widespread growth of applications to real-world problems caused a concomitant in-
crease in the demands for workable knowledge representation schemes. A large number of
different representation languages were developed. Some were based on logic—for example,
the Prolog language became popular in Europe, and the PLANNER family in the United States.
Others, following Minsky's idea of frames (1975), adopted a rather more structured approach,
collecting together facts about particular object and event types, and arranging the types into a
large taxonomic hierarchy analogous to a biological taxonomy.
