 

Introduction

This part contains a selection of algorithmic topics that extend and complement
earlier material in this book. Some chapters introduce new models of computation
such as circuits or parallel computers. Others cover specialized domains such as
computational geometry or number theory. The last two chapters discuss some of
the known limitations to the design of efficient algorithms and introduce techniques
for coping with those limitations.

Chapter 27 presents an algorithmic model for parallel computing based on dy-
namic multithreading. The chapter introduces the basics of the model, showing
how to quantify parallelism in terms of the measures of work and span. It then
investigates several interesting multithreaded algorithms, including algorithms for
matrix multiplication and merge sorting.

Chapter 28 studies efficient algorithms for operating on matrices. It presents
two general methods—LU decomposition and LUP decomposition—for solving
linear equations by Gaussian elimination in O(n) time. It also shows that matrix
inversion and matrix multiplication can be performed equally fast. The chapter
concludes by showing how to compute a least-squares approximate solution when
a set of linear equations has no exact solution.

Chapter 29 studies linear programming, in which we wish to maximize or mini-
mize an objective, given limited resources and competing constraints. Linear pro-
gramming arises in a variety of practical application areas. This chapter covers how
to formulate and solve linear programs. The solution method covered is the sim-
plex algorithm, which is the oldest algorithm for linear programming. In contrast
to many algorithms in this book, the simplex algorithm does not run in polynomial
time in the worst case, but it is fairly efficient and widely used in practice.
