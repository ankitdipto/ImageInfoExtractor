490 CHAPTER THIRTEEN Multiprocessors

microprocessor

Vist

Although some large-scale computers include two or more CPUs in their
overall system, it is the emergence of the microprocessor that has been the
major motivation for multiprocessor systems. The fact that microprocessors
take very little physical space and are very inexpensive brings about the
feasibility of interconnecting a large number of microprocessors into one com-
posite system. Very-large-scale integrated circuit technology has reduced the
Cost of computer components to such a low level that the concept of applying
multiple processors to meet system performance requirements has become an
attractive design possibility.

Multiprocessing improves the reliability of the system so that a failure or
error in one part has a limited effect on the rest of the system. If a fault causes
‘one processor to fail, a second processor can be assigned to perform the
functions of the disabled processor. The system as a whole can continue to
function correctly with perhaps some loss in effidency.

The benefit derived from a multiprocessor organization is an improved
system performance. The system derives its high performance from the fact
that computations can proceed in parallel in one of two ways.

1. Multiple independent jobs can be made to operate in parallel.
2. A single job can be partitioned into multiple parallel tasks.

‘An overall function can be partitioned into a number of tasks that each
processor can handle individually. System tasks may be allocated to special-
Purpose processors whose design is optimized to perform certain types of
processing efficiently. An example is acomputer system where one processor
performs the computations for an industrial process control while others
monitor and control the various parameters, such as temperature and flow
rate. Another example is a computer where one processor performs high-
speed floating-point mathematical computations and another takes care of
routine data-processing tasks.

Multiprocessing can improve performance by decomposing a program
into parallel executable tasks. This can be achievedin one of two ways. The user
can explicitly declare that certain tasks of the program be executed in parallel.
This must be done prior to loading the program by specifying the parallel
executable segments. Most multiprocessor manufacturers provide an operat-
ing system with programming language constructs suitable for specifying
parallel processing, The other, more efficient way is to provide a compiler with
multiprocessor software that can automatically detect parallelism in a user's
program. The compiler checks for data dependency in the program. If a program
depends on data generated in another part, the part yielding the needed data
must be executed first. However, two parts of a program that do not use data
generated by each can run concurrently. The parallelizing compiler checks the
entire program to detect any possible data dependencies. These that have no
data dependency are then considered for concurrent scheduling on different
processors.

 
