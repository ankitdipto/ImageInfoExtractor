Section 16.3.

Utility Functions 475

 

L. Utility principle
Ifan agent's preferences obey the axioms of utility, then there exists a real-valued function
U that operates on states such that U(A) > U(B) if and only if A is preferred to B, and
U(A)- U(B)if and only ifthe agent is indifferent between A and B.

U(A)> U(B) + A>B
U(A)= U(B) = A~B

2. Maximum Expected Utility principle
The utility of a lottery is the sum of the probabilities of each outcome times the utility of
that outcome.

Up, $15-+-3 Pa Sal) = Y- viUS))

In other words, once the probabilities and utilities of the possible outcome states are specified,
the utility ofa compound lottery involving these states can be computed. U([p, S13 p2, S2: °° ])
is completely determined by U/(S;)and the probability values.

It is important to remember that the existence ofa utility function that describes an agent's
preference behavior does not necessarily mean that the agent is explicitly maximizing that utility
function in its own deliberations. As we showed in Chapter 2, rational behavior can be generated
in any number of ways, some of which are more efficient than explicit utility maximization. By
observing an agent's preferences, however, it is possible to construct the utility function that
represents what it is that the agent's actions are trying to achieve.

16.3 UTILITY FUNCTIONS

Utility is a function that maps from states to real numbers. Is that all we can say about utility
functions? Strictly speaking, that is it. Beyond the constraints listed earlier, an agent can have
any preferences it likes. For example, an agent might prefer to have a prime number of dollars
in its bank account; in which case, ifit had $16 it would give away $3. It might prefer a dented
1973 Ford Pinto to a shiny new Mercedes. Preferences can also interact: for example, it might
only prefer prime numbers of dollars when it owns the Pinto, but when it owns the Mercedes, it
might prefer more dollars to less.

If all utility functions were as arbitrary as this, however, then utility theory would not
be of much help because we would have to observe the agent's preferences in every possible
combination of circumstances before being able to make any predictions about its behavior.
Fortunately, the preferences of real agents are usually more systematic. Conversely, there are
systematic ways of designing utility functions that, when installed in an artificial agent, cause it
to generate the kinds of behavior we want.
