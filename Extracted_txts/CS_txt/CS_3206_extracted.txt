568 Chapter 19. Leaming in Neural and Belief Networks

 

 

Notation | Meaning

 

 

 

 

 

 

qj Activation value of unit 7 (also the output of the unit) i

aj Vector of activation values for the inputs to unit 7 a

g Activation function |

g Derivative of the activation function ‘
Err; Entor (difference between output and target) for unit i :
Err’ Exror for example e

L Activation of a unit / in the input layer

I Vector of activations of all input units {

T Vector of inputs for example e |

in; Weighted sum of inputs to unit i §

N Total number of units in the network

 

oO Activation of the single output unit of a perceptron
Oj Activation ofa unit / in the output layer
Oo Vector of activations of all units in the output layer

 

 

 

t Threshold for a step function E
T Target (desired) output for a perceptron i
T Target vector when there are several output units
T Target vector for example e {
Wii Weight on the link from unity to unit i 4
WwW, Weight from unit r to the output in a perceptron
Ww, Vector of weights leading into unit 7
w Vector of all weights in the network

 

 

 

 

Figure 19.3. Neural network notation. Subscripts denote units; superscripts denote examples.

 

 

 

Input

Links

 

Input Activation
Function Function

Output

 

 

 

 

Figure 19.4 A unit.

 

 
