626

Chapter 21. Knowledge in Learning

 

ENTAILMENT
‘CONSTRAINT

 

We call this kind ofrelationship an entailment constraint, in which Hypothesis is the "unknown."
Pure inductive learning means solving this constraint, where Hypothesis is drawn from some
predefined hypothesis space. For example, if we consider a decision tree as a logical formula (see
page 532), then a decision tree that is consistent with all the examples will satisfy Equation (21.1).
If we place no restrictions on the logical form of the hypothesis, of course, then Hypothesis =
Classifications also satisfies the ‘constraint. Normally, Ockham's razor tells us to prefer small,
consistent hypotheses, so we try to do better than simply memorizing the examples.

This simple picture of inductive learning persisted until the early 1980s. The modern
approach is to design agents that already know something and are trying to learn some more.
This may not sound like a terrifically deep insight, but it makes quite a difference to the way in
which we write programs. It might also have some relevance to our theories about how science
itself works. The general idea is shown schematically in Figure 21.1.

 

 

Prior
knowledge

 

 

 

|

 
    
 

 

 

  

Knowledge-based

inductive learning Hypotheses | —e Predictions

Observations ——=

 

 

 

 

 

Figure 21.1 A cumulative learning process uses, and adds to, its stock of background knowl-
edge over time.

 

 

 

If we want to build an autonomous learning agent that uses background knowledge, the
agent must have some method for obtaining the background knowledge in the first place, in order
for it to be used in the new learning episodes. This method must itself be a learning process. The
agent's life history will therefore be characterized by cumulative, or incremental, development.
Presumably, the agent could start out with nothing, performing inductions in vacuo like a good
little pure induction program. But once it has eaten from the Tree of Knowledge, it can no longer
pursue such naive speculations, and should use its back ground knowledge to learn more and more
effectively. The question is then how to actually do this.

Some simple examples

Let us consider some commonsense examples of learning with background knowledge. Many
apparently rational cases of inferential behavior in the face of observations clearly do not follow
the simple principles of pure induction.

* Sometimes one leaps to general conclusions after only one observation. Gary Larson once
drew a cartoon in which a bespectacled caveman, Thag, is roasting his lizard on the end of
a pointed stick. He is watched by an amazed crowd of his less intellectual contemporaries,
who have been using their bare hands to hold their victuals over the fire. This enlightening
experience is enough to convince the watchers of a general principle of painless cooking.
