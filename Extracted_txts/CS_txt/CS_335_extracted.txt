16 Chapter 1. Introduction

 

Modern linguistics and AI were "born" at about the same time, so linguistics does not play
a large foundational role in the growth of AI. Instead, the two grew up together, intersecting
in a hybrid field called computational linguistics or natural language processing, which
concentrates on the problem of language use.

1.3 THE HISTORY OF ARTIFICIAL INTELLIGENCE

With the background material behind us, we are now ready to outline the development of AI
proper. We could do this by identifying loosely defined and overlapping phases in its development,
or by chronicling the various different and intertwined conceptual threads that make up the field.
In this section, we will take the former approach, at the risk of doing some degree of violence
to the real relationships among subfields. The history of each subfield is covered in individual
chapters later in the book.

The gestation of artificial intelligence (1943-1956)

The first work that is now generally recognized as AI was done by Warren McCulloch and
Walter Pitts (1943). They drew on three sources: knowledge of the basic physiology and
function of neurons in the brain; the formal analysis of propositional logic due to Russell and
Whitehead; and Turing's theory of computation. They proposed a model of artificial neurons in
which each neuron is characterized as being "on" or "off," with a switch to "on" occurring in
response to stimulation by a sufficient number of neighboring neurons. The state of a neuron
was conceived ofas "factually equivalent to a proposition which proposed its adequate stimulus."
They showed, for example, that any computable function could be computed by some network
of connected neurons, and that all the logical connectives could be implemented by simple
net structures. McCulloch and Pitts also suggested that suitably defined networks could leam.
Donald Hebb (1949) demonstrated a simple updating rule for modifying the connection strengths
between neurons, such that learning could take place.

The work of McCulloch and Pitts was arguably the forerunner of both the logicist tradition
in AI and the connectionist tradition. In the early 1950s, Claude Shannon (1950) and Alan
Turing (1953) were writing chess programs for von Neumann-style conventional computers.'*
At the same time, two graduate students in the Princeton mathematics department, Marvin
Minsky and Dean Edmonds, built the first neural network computer in 1951, The SNARC, as
it was called, used 3000 vacuum tubes and a surplus automatic pilot mechanism from a B-24
bomber to simulate a network of 40 neurons. Minsky's Ph.D. committee was skeptical whether
this kind of work should be considered mathematics, but von Neumann was on the committee
and reportedly said, "If it isn't now it will be someday." Ironically, Minsky was later to prove
theorems that contributed to the demise of much of neural network research during the 1970s.

12 Shannon actually had no real computer to work with, and Turing was eventually denied access to his own team's
computers by the British government, on the grounds that research into artificial intelligence was surely frivolous.
