822 Chapter 26. Philosophical Foundations

 

discriminatory behaviors associated with the beliefs "the light is red" or "the light is green," for
example. But it cannot distinguish between the experiences of red and green—what it is like to
see red as opposed to what itis liketo see green. It does seem that there is a real question here, but
itis not one that seems likely to yield to a behavioral analysis. Ifthe intrinsic experiences arising
from exposure to red and green lights were somehow switched, it seems reasonable to suppose
that we would still behave the same way at traffic lights, but it also seems reasonable to say
that our lives would be in some way different. This final aspect of intentional states—their "felt
quality" if you like—is by far the most problematic. It brings up the question of consciousness,
which, as we will see, is very ticklish indeed.

 

26.3__ON THE POSSIBILITY OF ACHIEVING INTELLIGENT BEHAVIOR

 

 

 

One of the most basic philosophical questions for AI is "Can machines think?" We will not
attempt to answer this question directly, because it is not clearly defined. To see why, consider
the following questions:

* Can machines fly?
* Can machines swim?

Most people would agree that the answer to the first question is yes, airplanes can fly, but the
answer to the second is no; boats and submarines do move through the water, but we do not
normally call that swimming. However, neither the questions nor the answers have any impact
at all on the working lives of aeronautic and naval engineers. The answers have very little to do
with the design or capabilities of airplanes and submarines, and much more to do with the way
we have chosen to use words. The word "swim" has come to mean "to move along in the water
by movements of the limbs or other body parts," whereas the word "fly" has no such limitation
on the means of locomotion.

To complicate matters, words can be used metaphorically, so when we say a computer
(or an engine, or the economy) is running well, we mean it is operating smoothly, not that it is
propelling itself with its legs in an admirable fashion. Similarly, a person who says, "My modem
doesn't work because the computer thinks it is a 2400-baud line" is probably using "thinks"
metaphorically, and may still maintain that computers do not /iterally think.

The practical possibility of "thinking machines" has been with us only for about 40 years,
not long enough for speakers of English to settle on an agreed meaning for the word "think." In
the early days of the debate, some philosophers thought that the question of thinking machines
could be settled by means of linguistic analysis of the kind hinted at earlier. Ifwe define "think"
to mean something like "make decisions or deliberations by means of an organic, natural brain,"
then we must conclude that computers cannot think. Ultimately, the linguistic community will
come to a decision that suits its need to communicate clearly, but the decision will not tell us
much about the capabilities of machines.

5 Wittgenstein said that we should "look at the word ‘to think’ as a tool.”

 
