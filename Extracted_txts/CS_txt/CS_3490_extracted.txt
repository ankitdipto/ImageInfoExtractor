 

Section 26.3.

On the Possibility of Achieving Intelligent Behavior 823

 

Alan Turing, in his famous paper "Computing Machinery and Intelligence" (Turing, 1950),
suggested that instead of asking "Can machines think?" we should instead ask if they can pass
a behavioral test (which has come to be called the Turing Test) for intelligence. He conjectured
that by the year 2000, a computer with a storage of 10Â° units could be programmed well enough
to have a conversation with an interrogator for 5 minutes and have a 30% chance of fooling the
interrogator into thinking it was human. Although we would certainly not claim that anything
like general, human-level intelligence will be achieved by that time, his conjecture may not be
that far off the truth. Turing also examined a wide variety of possible objections to the possibility
of intelligent machines, including virtually all of those that have been raised in the 44 years since
his paper appeared.

Some of the objections can be overcome quite easily. For example, Lady Ada Lovelace,
commenting on Babbage's Analytical Engine, says, "It has no pretensions to originate anything.
It can do whatever we know how to order it to perform." This objection, that computers can only
do what they are told to do and are therefore not capable of creativity, is commonly encountered
even today. It is refuted simply by noting that one of the things we can tell them to do is to leam
from their experience. For example, Samuel's checker-playing program performed very poorly
with its original programming. However, it was able to learn, over the course of a few days
of self-play, to play checkers far better than Samuel himself (see Chapter 20). One can try to
preserve Lady Lovelace's objection by maintaining that the program's ability to learn originated
in Samuel, and so too did its checker-playing ability. But then one would also be led to say that
Samuel's creativity originated in his parents, and theirs originated in their parents, and so on.

The "argument from disability" takes the form ofa claim, usually unsupported, to the effect
that "a machine can never do X" As examples of.X, Turing lists the following:

Be kind, resourceful, beautiful, friendly, have initiative, have a sense of humor, tell right from
wrong, make mistakes, fall in love, enjoy strawberries and cream, make someone fall in love
with it, leam from experience, use words properly, be the subject of its own thought, have as
much diversity of behavior as man, do something really new.

Although some of these abilities concem the consciousness of machines, which we discuss at
length in what follows, many concern behavioral properties (see Exercise 26.1). Turing suggests
that scepticism of this nature arises from experience of machines as devices for carrying out
Tepetitive tasks requiring little sensory and no reasoning ability. He points to the fact that in the
late 1940s, the general population found it difficult to believe that machines could find numerical
solutions of equations or predict ballistic trajectories. Even today, however, many technically
literate people do not believe that machines can learn.

The supposed inability to make mistakes presents an interesting problem when considering
the Turing Test. Certainly, instantaneous and correct answers to long division problems would
be a giveaway, and some attempt to simulate human fallibility would be required. But this is not
a mistake in the normal sense, because the program is doing exactly what its designer intended.
Something more akin to human mistakes will arise when intractable problems are involved. For
example, given only a small amount of time to find a chess move, the computer must essentially
guess that its move is correct. Similarly, a program that is trying to induce hypotheses from

6 Inrecent Turing Test competitions, the winning programs are those that type their answers back slowly and irregularly,
with occasional corrections and spelling mistakes. A Markov model of typing speed and accuracy is sufficient

 
