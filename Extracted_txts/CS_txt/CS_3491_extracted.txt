824

Chapter 26. Philosophical Foundations

 

HALTING PROBLEM

a small amount of data is bound to make mistakes when using such hypotheses for prediction.
When unavoidably irrational behavior on the part of the computer matches corresponding failings
ofhumans, this provides evidence that similar mechanisms are in operation. Rational behavior,
on the other hand, provides much weaker constraints on mechanisms.

What Turing calls the mathematical objection concems the proven inability of computers
to answer certain questions. We discuss this in-principle barrier to intelligence in Section 263.
In-practice objections center on the so-called "argument from informality," which claims that
intelligent behavior cannot be captured by formal rules. We discuss this category of objections in
Section 26.3. The final, and most interesting, objection claims that even if computers behave as
intelligently as humans, they still will not be intelligent. Although AI cannot do much more than
make machines behave intelligently, we still have some fun discussing the issue in Section 26.4.

The mathematical objection

It is well-known, partly through the work of Turing himself (Turing, 1936) as well as that of
Godel (1931), that certain questions cannot be answered correctly by any formal system. An
example is the halting problem: will the execution ofa program P eventually halt, or will it run
forever? Turing proved that for any algorithm H that purports to solve halting problems there
will always be a program P; such that H will not be able to answer the halting problem correctly.
Turing therefore acknowledges that for any particular machine that is being subjected to the
Turing Test, the interrogator can formulate a halting problem that the machine cannot answer
correctly.

Philosophers such as Lucas (1961) have claimed that this limitation makes machines
inferior to humans, who can always "step outside" the limiting logic to see whether the problem
in question is true or not. Lucas bases his argument not on the halting problem but on Gédel’s
incompleteness theorem (see Chapter 9). Briefly, for any non-trivial formal system F (a formal
language, and a set of axioms and inference rules), it is possible to construct a so-called "Godel
sentence" G(F) with the following properties:

* G(F) is a sentence of F, but cannot be proved within F.
+ IfF is consistent, then G(F) is true

Lucas claims that because a computer is a formal system, in a sense that can be made precise,
then there are sentences whose truth it cannot establish—namely, its own Godel sentences. A
human, on the other hand, can establish the truth ofthese sentences by applying Godel's theorem
to the formal system that describes the computer and its program.

Lucas's point is essentially the same as the potential objection raised by Turing himself,
and can be refuted in the same way. We admit that there is a strong intuition that human
mathematicians can switch from one formalism to another until they find one that solves the
problem they are faced with. But there is no reason why we could not have the same intuition
about a computer that was programmed to try thousands of different formalisms (and to invent
new formalisms) in an attempt to solve the halting or Godel problem. If we accept that the brain
is a deterministic physical device operating according to normal physical laws, then it is just
as much a formal system as the computer (although a harder one to analyze), and thus has the
same limitations as computers. If you believe there are nondeterministic aspects of the world

 
