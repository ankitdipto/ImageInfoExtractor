Section 26.4. Intentionality and Consciousness 331

 

Jefferson's key point is consciousness: the machine has to be aware ofits own mental state and
actions. Others focus on intentionality, that is, the“aboutness” (or lack thereof) of the machine's
purported beliefs, desires, intentions, and so on.

Turing's response to the objection is interesting. He could have presented reasons why
machines can in fact be conscious. But instead he maintains that the question is just as ill-
defined as asking "can machines think," and in any case, why should we insist on a higher
standard for machines than we do for humans? After all, in ordinary life we never have any
evidence about the internal mental states of other humans, so we cannot know that anyone else
is conscious. Nevertheless, "instead of arguing continually over this point, it is usual to have the
polite convention that everyone thinks," as Turing puts it.

Turing argues that Jefferson would be willing to extend the polite convention to machines
if only he had experience with ones that act intelligently, as in the following dialog, which has
become such a part of AI’s oral tradition that we simply have to include it:

 

HUMAN: In the first line of your sonnet which reads ‘shall I compare thee to a summer's day,’

would not a ‘spring day’ do as well or better?

MACHINE: It wouldn't scan.

HUMAN: How about ‘a winter's day’. That would scan all right.

MACHINE: Yes, but nobody wants to be compared to a winter's day.

HUMAN: Would you say Mr. Pickwick reminded you of Christmas?

MACHINE: In a way.

HUMAN: Yet Christmas is a winter's day, and I do not think Mr. Pickwick would mind the

comparison.

MACHINE: I don't think you're serious. By a winter's day one means a typical winter's day,

rather than a special one like Christmas.
Jefferson's objection is still an important one, because it points out the difficulty of establishing
any objective test for consciousness, where by "objective" we mean a test that can be carried out
with consistent results by any sufficiently competent third party. Turing also concedes that the
question of consciousness is not easily dismissed: "I do not wish to give the impression that I
think there is no mystery about consciousness ... But I do not think these mysteries necessarily
need to be solved before we can answer the question with which we are concerned in this paper,"
namely, "Can machines think?"

Although many, including Jefferson, have claimed that thinking necessarily involves con-
sciousness, the issue is most commonly associated with the work of the philosopher John Searle.
We will now discuss two thought experiments that, Searle claims, refute the thesis of strong AI.

The Chinese Room

We begin with the Chinese Room argument (Searle, 1980). The idea is to describe a hypothetical
system that is clearly running a program and passes the Turing Test, but that equally clearly
(according to Searle) does not understand anything of its inputs and outputs. The conclusion will
be that running the appropriate program (i.e., having the right outputs) is not a sufficient condition
for being a mind.

The system consists of a human, who understands only English, equipped with a rule
book, written in English, and various stacks of paper, some blank, some with indecipherable

 
