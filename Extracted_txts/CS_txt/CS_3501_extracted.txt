 

Section 26.4.

Intentionality and Consciousness 833

 

EMERGENT
PROPERTY.

 

be nothing to have understanding except the human; and again, when one asks the human (in
English), the reply will be in the negative.

Now we are down to the real issues. The shift from paper to memorization is a red herring,
because both forms are simply physical instantiations of arunning program. The real claim made
by Searle has the following form:

1. Certain kinds of objects are incapable of conscious understanding (of Chinese).
2. The human, paper, and rule book are objects of this kind.

3. If each of a set of objects is incapable of conscious understanding, then any system.
constructed from the objects is incapable of conscious understanding

4. Therefore there is no conscious understanding in the Chinese room.

While the first two steps are on firm ground," the third is not. Searle just assumes it is true
without giving any support for it. But notice that if you do believe it, and if you believe that
humans are composed of molecules, then either you must believe that humans are incapable of
conscious understanding, or you must believe that individual molecules are capable.

It is important to see that the rebuttal of Searle’s argument lies in rejecting the third step,
and not in making any claims about the room. You can believe that the room is not conscious
(or you can be undecided about the room's consciousness) and still legitimately reject Searle's
argument as invalid.

Searle's (1992) more recent position, described in his book The Rediscovery ofthe Mind,
is that consciousness is an emergent property of appropriately arranged systems of neurons
in the same way that solidity is an emergent property of appropriately arranged collections of
molecules, none of which are solid by themselves.

Now most supporters of strong Al would also say that consciousness is an emergent
property of systems of neurons (or electronic components, or whatever). The question is, which
properties of neurons are essential to consciousness, and which are merely incidental? In a
solid, what counts are the forces that molecules exert on each other, and the way in which those
forces change with distance. The solid would still be solid if we replaced each molecule with
a tiny computer connected to electromagnetic force field generators. As yet, we do not know
which properties of neurons are important—the functional properties associated with information
processing or the intrinsic properties of the biological molecules. The Chinese Room argument
therefore can be reduced to the empirical claim that the only physical medium that can support
consciousness is the neural medium. The only empirical evidence for this empirical claim is that
other media do not resemble neurons in their intrinsic physical properties. Searle (1992) admits
that it is possible that other media, including silicon, might support consciousness, but he would
claim that in such cases, the system would be conscious by virtue ofthe physical properties of
the medium and not by virtue of the program it was running.

To reiterate, the aim of the Chinese Room argument is to refute strong Al—the claim that
running the right sort of program necessarily generates consciousness. It does this by exhibiting
an apparently intelligent system running the right sort of program that is, according to Searle,
demonstrablyunconscious. He tried to demonstrate this with the argument that unconscious parts

13 Searle never explicitly says what kinds of objects are incapable of consciousness. Books and papers for sure, but he
wants us to generalize this to computers but not brains without saying exactly what the generalization is

 
