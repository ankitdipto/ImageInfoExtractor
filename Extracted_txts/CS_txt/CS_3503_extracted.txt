Section 26.4.

Intentionality and Consciousness 835

The Brain Prosthesis Experiment

The Brain Prosthesis Experiment was touched on by Searle (1980), but is most commonly
associated with the work of Hans Moravec (1988). It goes like this. Suppose we have developed
neurophysiology to the point where the input/output behavior and connectivity of all the neurons
in the brain are perfectly understood. Furthermore, suppose that we can build microscopic
electronic devices that mimic this behavior and can be smoothly interfaced to neural tissue.
Lastly, suppose that some miraculous surgical technique can replace individual neurons with
the corresponding electronic devices without interrupting the operation of the brain as a whole.
The experiment consists of gradually replacing all the neurons with electronic devices, and then
reversing the process to return the subject to his or her normal biological state.

We are concemed with both the extemal behavior and the internal experience ofthe subject,
during and after the operation. By the definition of the experiment, the subject's external behavior
must remain unchanged compared to what would be observed if the operation were not carried
out.'* Now although the presence or absence of consciousness cannot be easily ascertained by
a third party, the subject of the experiment ought at least to be able to record any changes in
his or her own conscious experience. Apparently, there is a direct clash of intuitions as to what
would happen. Moravec, a robotics researcher, is convinced his consciousness would remain
unaffected. He adopts the functionalist viewpoint, according to which the input/output behavior
of neurons is their only significant property. Searle, on the other hand, is equally convinced his
consciousness would vanish:

You find, to your total amazement, that you are indeed losing control of your extemal behavior.

You find, for example, that when doctors test your vision, you hear them say "We are holding

up a red object in front of you; please tell us what you see." You want to cry out "I can't see

anything. I'm going totally blind." But you hear your voice saying in a way that is completely

out of your control, "I see a red object in front of me." ... [Y]our conscious experience slowly

shrinks to nothing, while your externally observable behavior remains the same. (Searle, 1992)

But one can do more than argue from intuition. First, note that in order for the external behavior
to remain the same while the subject gradually becomes unconscious, it must be the case that the
subject's volition is removed instantaneously and totally, otherwise the shrinking of awareness
would be reflected in external behavior—Help, I'm shrinking!" or words to that effect. This
instantaneous removal of volition as a result of gradual neuron-at-a-time replacement seems an
unlikely claim to have to make.

Second, consider what happens if we do ask the subject questions concerning his or her
conscious experience during the period when no real neurons remain. By the conditions of the
experiment, we will get responses such as "I feel fine. I must say I'm a bit surprised because I
believed the Chinese Room argument." Or we might poke the subject with a pointed stick, and
observe the response, "Ouch, that hurt." Now, in the normal course of affairs, the sceptic can
dismiss such outputs from AI programs as mere contrivances. Certainly, it is easy enough to use
atule such as "If sensor 12 reads “High’ then print ‘Ouch.’ * But the point here is that because we
have replicated the functional properties of a normal human brain, we assume that the electronic
brain contains no such contrivances. Then we must have an explanation of the manifestations of

14 One can imagine using an identical "control" subject who is given a placebo operation, so that the two behaviors can
be compared.

 
