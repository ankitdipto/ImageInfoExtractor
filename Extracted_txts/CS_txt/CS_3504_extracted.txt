 

836

Chapter 26. Philosophical Foundations

 

EPIPHENOMENAL

"consciousness" produced by the electronic brain that appeals only to the functional properties
of the neurons. And this explanation must also apply to the real brain, which has the same
Junctional properties. There are, it seems, only two possible conclusions:

1. The causal mechanisms involved in consciousness that generate these kinds of outputs in
normal brains are still operating in the electronic version, which is therefore "conscious."

2. The conscious mental events in the normal brain have no causal connection to the subject's
behavior, and are missing from the electronic brain.

Although we cannot rule out the second possibility, itreduces consciousness to what philosophers
call an epiphenomenal role—something that happens but casts no shadow, as it were, on the
observable world. Furthermore, if consciousness is indeed epiphenomenal, then the brain must
contain a second, unconscious mechanism that is responsible for the "Ouch."

Third, consider the situation after the operation has been reversed and the subject has a
normal brain. Once again, the subject's external behavior must be as if the operation had not
occurred. In particular, we should be able to ask, "What was it like during the operation? Do
you remember the pointed stick?" The subject must have accurate memories of the actual nature
ofhis or her conscious experiences, including the qualia, despite the fact that according to Searle
there were no such experiences

Searle might reply that we have not specified the experimental conditions properly. If the
real neurons are, say, put into suspended animation between the time they are extracted and the
time they are replaced in the brain, then of course they will not "remember" the experiences
during the operation. To deal with this, we simply need to make sure that the neurons’ state is
updated, by some means, to reflect the internal state of the artificial neurons they are replacing.
If the supposed "nonfunctional" aspects of the real neurons then result in functionally different
behavior from that observed with artificial neurons still in place, then we have a simple reductio
ad absurdum, because that would mean that the artificial neurons are not functionally equivalent
to the real neurons. (Exercise 26.4 addresses a rebuttal to this argument.)

Patricia Churchland (1986) points out that the functionalist arguments that operate at the
level ofthe neuron can also operate at the level of any larger functional unit—a clump ofneurons,
a mental module, a lobe, a hemisphere, or the whole brain. That means that if you accept that the
brain prosthesis experiment shows that the replacement brain is conscious, then you should also
believe that consciousness is maintained when the entire brain is replaced by a circuit that maps
from inputs to outputs via a huge lookup table. This is disconcerting to many people (including
Turing himself) who have the intuition that lookup tables are not conscious.

Discussion

We have seen that the subject of consciousness is problematic. Simple intuitions seem to lead
to conflicting answers if we propose different experimental situations. But what is clear is
that ifthere is an empirical question concerning the presence or absence of consciousness in
appropriately programmed computers, then like any empirical question it can only be settled by
experiment. Unfortunately, it is not clear what sort of experiment could settle the question, nor
what sort of scientific theory could explain the results. Scientific theories are designed to account
for objective phenomena; in fact Popper (1962) has characterized all physical laws as theories

 

 

 

 
