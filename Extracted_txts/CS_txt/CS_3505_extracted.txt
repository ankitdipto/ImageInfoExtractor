 

Section 26.5.

Summary 837

 

that, ultimately, allow one to conclude the existence of particles in certain space-time locations.
How would we view a theory that allowed one to infer pains, for example, from premises of the
ordinary physical kind? It seems that it would be at best a description ("When a voltage is applied
to such-and-such neuron, the subject will feel pain") rather than an explanation. An explanatory
theory should, among other things, be able to explain why it is pain that the subject experiences
when a given neuron is stimulated, rather than, say, the smell of bacon sandwiches.

It is also hard to imagine how a better understanding of neurophysiology could help.
Suppose, for example, that (1) we could train a subject to record all his or her conscious
thoughts without interrupting them too much; (2) neuroscientists discovered a system of neurons
whose activity pattems could be decoded and understood;! and (3) the decoded activity patterns
corresponded exactly to the recorded conscious thoughts. Although we might claim to have
located the "seat of consciousness," it seems we would still be no better offin our understanding
of why these patterns of activity actually constitute consciousness.

The problem seems to be that consciousness, as we currently (fail to) understand it, is not
understandable by the normal means available to science.

No one can rule out a major intellectual revolution that would give us a new—and at present
unimaginable—concept of reduction, according to which consciousness would be reducible.
(Searle, 1992,p. 124).

If consciousness is indeed irreducible, that would suggest that there can be no explanations in
nonsubjective terms of why red is the sort of sensation it is and not some other sort, or why pain
is like pain and not like the smell of bacon sandwiches.

One final (but not necessarily conclusive) argument can be made concerning the evolu-
tionary origin of consciousness. Both sides of the debate agree that simple animals containing
only a few neurons do not possess consciousness. In such animals, neurons fulfill a purely
functional role by allowing simple adaptive and discriminative behaviors. Yet the basic design
and construction of neurons in primitive animals is almost identical to the design of neurons in
higher animals. Given this observation, the proponent of consciousness as an intrinsic neural
phenomenon must argue that neurons, which evidently evolved for purely functional purposes,
just happen by chance to have exactly the properties required to generate consciousness. The
functionalist, on the other hand, can argue that consciousness necessarily emerges when systems
reach the kind of functional complexity needed to sustain complex behavior.

265 SUMMARY

We have presented some of the main philosophical issues in AI. These were divided into ques-
tions concerning its technical feasibility (weak AI), and questions conceming its relevance and
explanatory power with respect to the mind (strong AI). We concluded, although by no means
conclusively, that the arguments against weak AI are needlessly pessimistic and have often mis-
characterized the content of AI theories. Arguments against strong AI are inconclusive; although

15 It is not clear if this really makes sense, but the idea is to grant neuroscience as much success as we can imagine.

 
