 

Section 27.2.

What Exactly Are We Trying to Do? 847

 

ACTUTIUTARIANISM

RULE
UTLITARIANISM

GAME THEORY

PRISONERS.
DILEMMA

the processes that allow an agent program to converge to bounded optimality, and perhaps less
concentration on the details of the messy programs that result.

In summary, the concept of bounded optimality is proposed as a formal task for artificial
intelligence research that is both well-defined and feasible. Bounded optimality specifies optimal

programs rather than optimal actions. Actions are, after all, generated by programs, and it is over
programs that designers have control.

This move from prescribing actions to prescribing programs is not unique to Al. Philosophy
has also seen a gradual evolution in the definition of rationality. There has been a shift from
consideration of act utilitarianism—the rationality of individual acts—to rule utilitarianism,
or the rationality of general policies for acting. A philosophical proposal generally consistent
with the notion of bounded optimality can be found in the "Moral First Aid Manual" (Dennett,
1986). Dennett explicitly discusses the idea of reaching equilibrium within the space of feasible
configurations of decision procedures. He uses as an example the Ph.D. admissions procedure
ofa philosophy department. He concludes, as do we, that the best configuration may be neither
elegant nor illuminating. The existence of such a configuration and the process ofreaching it are
the main points of interest.

Another area to undergo the same transition is game theory, a branch of economics
initiated in the same book—Theory of Games and Economic Behavior (Von Neumann and
Morgenstern, 1944)—thatbegan the widespread study of decision theory. Game theory studies
decision problems in which the utility ofa given action depends not only on chance events in
the environment but also on the actions of other agents. The standard scenario involves a set of
agents who make their decisions simultaneously, without knowledge of the decisions of the other
agents. The Prisoner's Dilemma is a famous example, in which each of two crime suspects
can "collaborate" (refuse to implicate his or her partner) or "defect" (spill the beans in return
for a free pardon). Ifthe suspects collaborate, they will only be convicted of a minor offense,
a one-year sentence. If they both defect, both receive a four-year sentence. If one defects and
the other does not, the defector goes free whereas the other receives the maximum sentence of
ten years. Considered from the point of view of either player separately, the best plan is to
defect, because this gives better results whatever the other agent does. Unfortunately for the
suspects (but not for the police), this results in both suspects spilling the beans and receiving
a four-year sentence, whereas if they had collaborated, they would both have received lighter
sentences. Even more disturbing is the fact that defection also occurs when the game has a
finite number of rounds. (This can easily be proved by working backwards from the last round.)
Recently, however, there has been a shift from consideration of optimal decisions in games to
a consideration of optimal decision-making programs. This leads to different results because
it limits the ability of each agent to do unlimited simulation of the other, who is also doing
unlimited simulation of the first, and so on. Even the requirement of computability makes a
significant difference (Megiddo and Wigderson, 1986). Bounds on the complexity of players
have also become a topic of intense interest. Neyman’s theorem (Neyman, 1985), recently proved
by Papadimitriou and Yannakakis (1994), shows that a collaborative equilibrium exists if each
agent is a finite automaton with a number of states that is less than exponential in the number of
rounds. This is essentially a bounded optimality result, where the bound is on space rather than
speed of computation. Again, the bounded optimal program for the automaton is rather messy,
but its existence and properties are what counts.

 
