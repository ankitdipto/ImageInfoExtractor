848

Chapter 27. Al: Present and Future

 

27.3 WHAT IF WE Do Succeep?

In David Lodge's Small World, a novel about the academic world of literary criticism, the
protagonist causes consternation by asking a panel of eminent but contradictory literary theorists
the following question: "What ifyou were right?” None of the theorists seems to have considered
this question before, perhaps because debating unfalsifiable theories is an end in itself. Similar
confusion can sometimes be evoked by asking AI researchers, "What if you succeed?" AI is
fascinating, and intelligent computers are clearly more useful than unintelligent computers, so
why worry?

To the extent that AI has already succeeded in finding uses within society, we are now
facing some of the real issues. In the litigious atmosphere that prevails in the United States, it
is hardly surprising that legal liability needs to be discussed. When a physician relies on the
judgment of a medical expert system for a diagnosis, who is at fault if the diagnosis is wrong?
Fortunately, due in part to the growing influence of decision-theoretic methods in medicine, it is
now accepted that negligence cannot be shown if the physician performs medical procedures that
have high expected utility, even ifthe actual utility is catastrophic. The question should therefore
be, "Who is at faultifthe diagnosis is unreasonable?" So far, courts have held that medical expert
systems play the same role as medical textbooks and reference books; physicians are responsible
for understanding the reasoning behind any decision and for using their own judgment in deciding
whether or not to accept the system's recommendations. In designing medical expert systems
as agents, therefore, the actions should not be thought of as directly affecting the patient but
as influencing the physician's behavior. If expert systems become reliably more accurate than
human diagnosticians, doctors may be legally liable if they fail to use the recommendations of
an expert system.

Similar issues are beginning to arise regarding the use of intelligent agents on the "informa-
tion highway." Some progress has been made in incorporating constraints into intelligent agents
so that they cannot damage the files of other users (Weld and Etzioni, 1994). Also problematic
is the fact that network services already involve monetary transactions. If those monetary trans-
actions are made “on one's behalf" by an intelligent agent, is one liable for the debts incurred?
Would it be possible for an intelligent agent to have assets itselfand to perform electronic trades
on its own behalf? Could it own stocks and bonds in the same way that corporations own stocks
and bonds? So far, these questions do not seem to be well understood. To our knowledge, no
program has been granted legal status as an individual for the purposes of financial transactions;
at present, it seems unreasonable to do so. Programs are also not considered to be "drivers" for
the purposes of enforcing traffic regulations on real highways. In California law, at least, there
do not seem to be any legal sanctions to prevent an automated vehicle from exceeding the speed
limits, although the designer of the vehicle's control mechanism would be liable in the case of
accident. As with human reproductive technology, the law has yet to catch up with the new
developments. These topics, among others, are covered in journals such as AI and Society, Law,
Computers and Artificial Intelligence, and Artificial Intelligence and Law.

Looking further into the future, one can anticipate questions that have been the subject of
innumerable works of science fiction, most notably those of Asimov (1942). If we grant that

 

 
