 

Section 27.3.

What If We Do Succeed? 849

 

machines will achieve high levels of intelligent behavior and will communicate with humans as
apparent equals, then these questions are unavoidable. Should (or will) intelligent machines have
rights? How should intelligent machines interact with humans? What might happen if intelligent
machines decide to work against the best interests ofhuman beings? What if they succeed?

In Computer Power and Human Reason, Joseph Weizenbaum (the author of the ELIZA
program) has argued that the effect of intelligent machines on human society will be such that
continued work on artificial intelligence is perhaps unethical. One of Weizenbaum's principal
arguments is that AI research makes possible the idea that humans are automataâ€”an idea that
results in a loss of autonomy or even of humanity. (We note that the idea has been around
much longer than AI. See L'Homme Machine (La Mettrie, 1748).) One can perhaps group
such concerns with the general concem that any technology can be misused to the detriment of
humanity. Arguments over the desirability of a given technology must weigh the benefits and
tisks, and put the onus on researchers to ensure that policy makers and the public have the best
possible information with which to reach a decision. On the other hand, AI raises deeper questions
than, say, nuclear weapons technology. No one, to our knowledge, has suggested that reducing
the planet to a cinder is better than preserving human civilization. Futurists such as Edward
Fredkin and Hans Moravec have, however, suggested that once the human race has fulfilled its
destiny in bringing into existence entities ofhigher (and perhaps unlimited) intelligence, its own
preservation may seem less important. Something to think about, anyway.

Looking on the bright side, success in AI would provide great opportunities for improving
the material circumstances of human life. Whether it would improve the quality of life is an open
question. Will intelligent automation give people more fulfilling work and more relaxing leisure
time? Or will the pressures of competing in a nanosecond-paced world lead to more stress?
Will children gain from instant access to intelligent tutors, multimedia online encyclopedias, and
global communication, or will they play ever more realistic war games? Will intelligent machines
extend the power of the individual, or of centralized governments and corporations? Science
fiction authors seem to favor dystopian futures over Utopian ones, probably because they make
for more interesting plots. In reality, however, the trends seem not to be too terribly negative.

 
