Section 1,3.

The History of Artificial Intelligence 21

 

MACHINE EVOLUTION

 

on any topic, actually just borrowed and manipulated the sentences typed into it by a human.
A typical story occurred in early machine translation efforts, which were generously funded by
the National Research Council in an attempt to speed up the translation of Russian scientific
papers in the wake of the Sputnik launch in 1957. It was thought initially that simple syntactic
transformations based on the grammars of Russian and English, and word replacement using
an electronic dictionary, would suffice to preserve the exact meanings of sentences. In fact,
translation requires general knowledge of the subject matter in order to resolve ambiguity and
establish the content of the sentence, The famous retranslation of "the spirit is willing but the
flesh is weak’ as "the vodka is good but the meat is rotten" illustrates the difficulties encountered.
In 1966, a report by an advisory committee found that "there has been no machine translation
of general scientific text, and none is in immediate prospect." All U.S. government funding for
academic trarslation projects was cancelled.

The second kind of difficulty was the intractability of many of the problems that AT was
attempting tosolve. Most of the early AI programs worked by representing the basic facts about
a problem ani trying out a series of steps to solve it, combining different combinations of steps
until the right one was found. The early programs were feasible only because microworlds
contained ver few objects. Before the theory of NP-completeness was developed, it was widely
thought that "scaling up" to larger problems was simply a matter of faster hardware and larger
memories. The optimism that accompanied the development of resolution theorem proving, for
example, wa‘ soon dampened when researchers failed to prove theorems involving more than a
few dozen fatis. The fact that a program canfind a solution in principle does not mean that the
program conisins any ofthe mechanisms needed to find it in practice.

The illusion of unlimited computational power was not confined to problem-solving pro-
grams. Earl) experiments in machine evolution (now called genetic algorithms) (Friedberg,
1958; Friedberg et al., 1959) were based on the undoubtedly correct belief that by making an
appropriate series of small mutations to a machine code program, one can generate a program
with good performance for any particular simple task. The idea, then, was to try random muta-
tions and then apply a selection process to preserve mutations that seemed to improve behavior.
Despite thowands of hours of CPU time, almost no progress was demonstrated.

Failure to come to grips with the "combinatorial explosion" was one ofthe main criticisms
of AI contained in the Lighthill report (Lighthill, 1973), which formed the basis for the decision
by the British government to end support for AI research in all but two universities. (Oral
tradition painis a somewhat different and more colorful picture, with political ambitions and
personal animosities that cannot be put in print.)

A third difficulty arose because of some fundamental limitations on the basic structures
being used to generate intelligent behavior. For example, in 1969, Minsky and Papert's book
Perceptrons (1969) proved that although perceptrons could be shown to learn anything they were
capable of representing, they could represent very little. In particular, a two-input perceptron
could not be :rained to recognize when its two inputs were different. Although their results
did not appl to more complex, multilayer networks, research funding for neural net research
soon dwindled to almost nothing. Ironically, the new back-propagation learning algorithms for
multilayer networks that were to cause an enormous resurgence in neural net research in the late
1980s were actually discovered first in 1969 (Bryson and Ho, 1969).
