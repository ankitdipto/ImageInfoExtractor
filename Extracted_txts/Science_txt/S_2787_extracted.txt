598 CHAPTER 20 ENTROPY AND THE SECOND LAW OF THERMODYNAMICS.

Because the work done by engine X is equal to the work done on the Carnot
refrigerator, we have, from the first law of thermodynamics as given by Eq. 20-8,

|Qu] — |Q1] = |Qul — |i.
which we can write as
|Qul — |Qul = |Q1|- | Qi] = @.

Because of Eq. 20-18, the quantity Q in Eq. 20-19 must be positive.

Comparison of Eq. 20-19 with Fig. 20-16 shows that the net effect of engine
X and the Carnot refrigerator working in combination is to transfer energy Q as
heat from a low-temperature reservoir to a high-temperature reservoir without
the requirement of work. Thus, the combination acts like the perfect refrigerator
of Fig. 20-15, whose existence is a violation of the second law of thermodynamics.

Something must be wrong with one or more of our assumptions, and it can
only be Eq. 20-17. We conclude that no real engine can have an efficiency greater
than that of a Carnot engine when both engines work between the same two tem-
peratures. At most, the real engine can have an efficiency equal to that of a
Carnot engine. In that case, the real engine is a Carnot engine.

(20-19)

20-4 a sTATISTICAL VIEW OF ENTROPY

Learning Objectives
After reading this module, you should be able to...

 

20.21 Explain what is meant by the configurations of a system
of molecules.

20.22 Calculate the multiplicity of a given configuration.

20.23 Identify that all microstates are equally probable but

Key Ideas

the configurations with more microstates are more proba-
ble than the other configurations.

20.24 Apply Boltzmann's entropy equation to calculate the
entropy associated with a multiplicity.

 

@ The entropy of a system can be defined in terms of the pos-
sible distributions of its molecules. For identical molecules,
each possible distribution of molecules is called a microstate
of the system. All equivalent microstates are grouped into a
configuration of the system. The number of microstates in a
configuration is the multiplicity W of the configuration.
@ Forasystem of N molecules that may be distributed
between the two halves of a box, the multiplicity is given by
N!

ny! ny!”
in which nj is the number of molecules in one half of the box and
Ny is the number in the other half. A basic assumption of statisti-
cal mechanics is that all the microstates are equally probable.

Thus, configurations with a large multiplicity occur most
often. When Nis very large (say, N = 10” molecules or more),
the molecules are nearly always in the configuration in which
ny = Np.
@ The multiplicity W of a configuration of a system and the en-
tropy S of the system in that configuration are related by
Boltzmann's entropy equation:

S=kinW,
where k = 1.38 X 10-3 J/K is the Boltzmann constant.
@ When Nis very large (the usual case), we can approximate
In M! with Stirling's approximation:

InN! ~ N(in N) —N.

 

A Statistical View of Entropy

In Chapter 19 we saw that the macroscopic properties of gases can be explained
in terms of their microscopic, or molecular, behavior. Such explanations are part
of a study called statistical mechanics. Here we shall focus our attention on a sin-
gle problem, one involving the distribution of gas molecules between the two
halves of an insulated box. This problem is reasonably simple to analyze, and it al-
lows us to use statistical mechanics to calculate the entropy change for the free
expansion of an ideal gas. You will see that statistical mechanics leads to the same
entropy change as we would find using thermodynamics.
