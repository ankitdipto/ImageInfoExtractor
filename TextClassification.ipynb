{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras import Sequential,layers\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath='/home/ankit/Documents/ML/ImageInfoExtractor/datasets/Digital_Music_5.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_json(filePath, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3EBHHCZO6V2A4</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Amaranth \"music fan\"</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>It's hard to believe \"Memory of Trees\" came ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>Enya's last great album</td>\n",
       "      <td>1158019200</td>\n",
       "      <td>09 12, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AZPWAXJG9OJXV</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>bethtexas</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>A clasically-styled and introverted album, Mem...</td>\n",
       "      <td>5</td>\n",
       "      <td>Enya at her most elegant</td>\n",
       "      <td>991526400</td>\n",
       "      <td>06 3, 2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A38IRL0X2T4DPF</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>bob turnley</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>I never thought Enya would reach the sublime h...</td>\n",
       "      <td>5</td>\n",
       "      <td>The best so far</td>\n",
       "      <td>1058140800</td>\n",
       "      <td>07 14, 2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A22IK3I6U76GX0</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Calle</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>This is the third review of an irish album I w...</td>\n",
       "      <td>5</td>\n",
       "      <td>Ireland produces good music.</td>\n",
       "      <td>957312000</td>\n",
       "      <td>05 3, 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1AISPOIIHTHXX</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Cloud \"...\"</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Enya, despite being a successful recording art...</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5; music to dream to</td>\n",
       "      <td>1200528000</td>\n",
       "      <td>01 17, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64701</th>\n",
       "      <td>A1PQ1PESSO8CMO</td>\n",
       "      <td>B00KILDVEI</td>\n",
       "      <td>Ginger Christmas</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I like the reggae sound a lot in this song. I ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Cool song</td>\n",
       "      <td>1403568000</td>\n",
       "      <td>06 24, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64702</th>\n",
       "      <td>A120RH58WVY4W6</td>\n",
       "      <td>B00KILDVEI</td>\n",
       "      <td>Kelly Dunwell \"avid reader\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I first heard this on Sirius and had to have i...</td>\n",
       "      <td>5</td>\n",
       "      <td>Great Song</td>\n",
       "      <td>1404864000</td>\n",
       "      <td>07 9, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64703</th>\n",
       "      <td>A19VJ2IQLO50G0</td>\n",
       "      <td>B00KILDVEI</td>\n",
       "      <td>melinda</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>I absolutely love this song, it downloaded fin...</td>\n",
       "      <td>5</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1405209600</td>\n",
       "      <td>07 13, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64704</th>\n",
       "      <td>AUDSM2CTLLW1Q</td>\n",
       "      <td>B00KILDVEI</td>\n",
       "      <td>Patrick L. Randall</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Reggae, island beats aren't really my cup of t...</td>\n",
       "      <td>3</td>\n",
       "      <td>Well-crafted song</td>\n",
       "      <td>1404864000</td>\n",
       "      <td>07 9, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64705</th>\n",
       "      <td>A1GN8UJIZLCA59</td>\n",
       "      <td>B00KILDVEI</td>\n",
       "      <td>P Magnum</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>Magic! is a Canadian band that incorporates re...</td>\n",
       "      <td>1</td>\n",
       "      <td>Souless Reggae</td>\n",
       "      <td>1405641600</td>\n",
       "      <td>07 18, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64706 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           reviewerID        asin                 reviewerName helpful  \\\n",
       "0      A3EBHHCZO6V2A4  5555991584         Amaranth \"music fan\"  [3, 3]   \n",
       "1       AZPWAXJG9OJXV  5555991584                    bethtexas  [0, 0]   \n",
       "2      A38IRL0X2T4DPF  5555991584                  bob turnley  [2, 2]   \n",
       "3      A22IK3I6U76GX0  5555991584                        Calle  [1, 1]   \n",
       "4      A1AISPOIIHTHXX  5555991584                  Cloud \"...\"  [1, 1]   \n",
       "...               ...         ...                          ...     ...   \n",
       "64701  A1PQ1PESSO8CMO  B00KILDVEI             Ginger Christmas  [0, 0]   \n",
       "64702  A120RH58WVY4W6  B00KILDVEI  Kelly Dunwell \"avid reader\"  [0, 0]   \n",
       "64703  A19VJ2IQLO50G0  B00KILDVEI                      melinda  [0, 1]   \n",
       "64704   AUDSM2CTLLW1Q  B00KILDVEI           Patrick L. Randall  [0, 0]   \n",
       "64705  A1GN8UJIZLCA59  B00KILDVEI                     P Magnum  [1, 2]   \n",
       "\n",
       "                                              reviewText  overall  \\\n",
       "0      It's hard to believe \"Memory of Trees\" came ou...        5   \n",
       "1      A clasically-styled and introverted album, Mem...        5   \n",
       "2      I never thought Enya would reach the sublime h...        5   \n",
       "3      This is the third review of an irish album I w...        5   \n",
       "4      Enya, despite being a successful recording art...        4   \n",
       "...                                                  ...      ...   \n",
       "64701  I like the reggae sound a lot in this song. I ...        4   \n",
       "64702  I first heard this on Sirius and had to have i...        5   \n",
       "64703  I absolutely love this song, it downloaded fin...        5   \n",
       "64704  Reggae, island beats aren't really my cup of t...        3   \n",
       "64705  Magic! is a Canadian band that incorporates re...        1   \n",
       "\n",
       "                            summary  unixReviewTime   reviewTime  \n",
       "0           Enya's last great album      1158019200  09 12, 2006  \n",
       "1          Enya at her most elegant       991526400   06 3, 2001  \n",
       "2                   The best so far      1058140800  07 14, 2003  \n",
       "3      Ireland produces good music.       957312000   05 3, 2000  \n",
       "4            4.5; music to dream to      1200528000  01 17, 2008  \n",
       "...                             ...             ...          ...  \n",
       "64701                     Cool song      1403568000  06 24, 2014  \n",
       "64702                    Great Song      1404864000   07 9, 2014  \n",
       "64703                    Five Stars      1405209600  07 13, 2014  \n",
       "64704             Well-crafted song      1404864000   07 9, 2014  \n",
       "64705                Souless Reggae      1405641600  07 18, 2014  \n",
       "\n",
       "[64706 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdf=df[[\"reviewText\",\"summary\",\"overall\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's hard to believe \"Memory of Trees\" came ou...</td>\n",
       "      <td>Enya's last great album</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A clasically-styled and introverted album, Mem...</td>\n",
       "      <td>Enya at her most elegant</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I never thought Enya would reach the sublime h...</td>\n",
       "      <td>The best so far</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is the third review of an irish album I w...</td>\n",
       "      <td>Ireland produces good music.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Enya, despite being a successful recording art...</td>\n",
       "      <td>4.5; music to dream to</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  \\\n",
       "0  It's hard to believe \"Memory of Trees\" came ou...   \n",
       "1  A clasically-styled and introverted album, Mem...   \n",
       "2  I never thought Enya would reach the sublime h...   \n",
       "3  This is the third review of an irish album I w...   \n",
       "4  Enya, despite being a successful recording art...   \n",
       "\n",
       "                        summary  overall  \n",
       "0       Enya's last great album        5  \n",
       "1      Enya at her most elegant        5  \n",
       "2               The best so far        5  \n",
       "3  Ireland produces good music.        5  \n",
       "4        4.5; music to dream to        4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=subdf['reviewText'].values\n",
    "y=subdf['overall'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train, sentences_test, y_train, y_test=\\\n",
    "train_test_split(sentences,y,test_size=0.20,random_state=62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(lowercase=False, min_df=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer=CountVectorizer(min_df=0, lowercase=False)\n",
    "vectorizer.fit(sentences_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=vectorizer.transform(sentences_train)\n",
    "X_test=vectorizer.transform(sentences_test)\n",
    "y_train=y_train.reshape(-1,1)\n",
    "y_test=y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoder=OneHotEncoder(sparse=False)\n",
    "one_hot_encoder.fit(y_train)\n",
    "encoded_y_train=one_hot_encoder.transform(y_train)\n",
    "encoded_y_test=one_hot_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "[[0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_y_train)\n",
    "print(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clfBase=LogisticRegression(max_iter=1400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (51764, 5) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9d99afbfbe5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclfBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoded_y_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscoreBase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclfBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoded_y_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DL/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1342\u001b[0m         X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[1;32m   1343\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m                                    accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1345\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DL/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DL/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DL/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    805\u001b[0m                         ensure_2d=False, dtype=None)\n\u001b[1;32m    806\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DL/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DL/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    845\u001b[0m     raise ValueError(\n\u001b[1;32m    846\u001b[0m         \u001b[0;34m\"y should be a 1d array, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m         \"got an array of shape {} instead.\".format(shape))\n\u001b[0m\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (51764, 5) instead."
     ]
    }
   ],
   "source": [
    "#clfBase.fit(X_train,encoded_y_train)\n",
    "#scoreBase=clfBase.score(X_test,encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(scoreBase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clfNN=Sequential()\n",
    "clfNN.add(layers.Dense(7,input_dim=X_train.shape[1],activation='sigmoid'))\n",
    "clfNN.add(layers.Dense(8,activation='sigmoid'))\n",
    "clfNN.add(layers.Dense(5,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfNN.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 7)                 948773    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 8)                 64        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 5)                 45        \n",
      "=================================================================\n",
      "Total params: 948,882\n",
      "Trainable params: 948,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clfNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51764, 135538)\n",
      "(51764, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove './logs/fit/*': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "\"\"\"!rm -r ./logs/fit/*\n",
    "logDirPath='logs/fit/'+datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboardCallback=tf.keras.callbacks.TensorBoard(log_dir=logDirPath,histogram_freq=1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,accuracy=clfNN.evaluate(X_train,encoded_y_train,verbose=False)\n",
    "print(\"Training Accuracy: {:.6f} and Loss: {:.7f}\".format(accuracy,loss))\n",
    "loss,accuracy=clfNN.evaluate(X_test,encoded_y_test,verbose=False)\n",
    "print(\"Testing  Accuracy: {:.6f} and Loss: {:.7f}\".format(accuracy,loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=1049, output_dim=8, input_length=X_train.shape[1]))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(5, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def trainInBatch(model,batch_size,X_train,y_train):\n",
    "    print(\"No. of training examples: \",X_train.shape[0])\n",
    "    numOfBatches=X_train.shape[0]//batch_size\n",
    "    for idx in range(numOfBatches):\n",
    "        start=idx*batch_size\n",
    "        stop=min((idx+1)*batch_size,X_train.shape[0])\n",
    "        model.fit(X_train[start:stop][:],y_train[start:stop])\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model,X,y,batch_size):\n",
    "    y_pred=np.zeros(y.shape)\n",
    "    numOfBatches=X.shape[0]//batch_size\n",
    "    cnt=0\n",
    "    for idx in range(numOfBatches):\n",
    "        start=idx*batch_size\n",
    "        stop=min((idx+1)*batch_size,X.shape[0])\n",
    "        y_pred[start:stop][:]=model.predict(X[start:stop][:])\n",
    "    return (y_pred==y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training examples:  51764\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 855us/sample - loss: 1.8191 - acc: 0.1675\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 814us/sample - loss: 1.6933 - acc: 0.2817\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 802us/sample - loss: 1.6300 - acc: 0.2425\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 787us/sample - loss: 1.5516 - acc: 0.2517\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 799us/sample - loss: 1.5002 - acc: 0.2542\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 810us/sample - loss: 1.4463 - acc: 0.2500\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 859us/sample - loss: 1.3870 - acc: 0.2717\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 821us/sample - loss: 1.3609 - acc: 0.4542\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 852us/sample - loss: 1.3214 - acc: 0.5417\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 839us/sample - loss: 1.2788 - acc: 0.5342\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 816us/sample - loss: 1.2418 - acc: 0.5625\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 812us/sample - loss: 1.2099 - acc: 0.5550\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 828us/sample - loss: 1.2050 - acc: 0.5367\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 841us/sample - loss: 1.2267 - acc: 0.5400\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 821us/sample - loss: 1.2136 - acc: 0.5417\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 843us/sample - loss: 1.1921 - acc: 0.5475\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 824us/sample - loss: 1.2031 - acc: 0.5383\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 819us/sample - loss: 1.1731 - acc: 0.5650\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 852us/sample - loss: 1.1678 - acc: 0.5458\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 996us/sample - loss: 1.2162 - acc: 0.5250\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 1ms/sample - loss: 1.1571 - acc: 0.5633\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 1ms/sample - loss: 1.2151 - acc: 0.5333\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 842us/sample - loss: 1.1642 - acc: 0.5558\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 837us/sample - loss: 1.1666 - acc: 0.5508\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 1ms/sample - loss: 1.1812 - acc: 0.5500\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 1ms/sample - loss: 1.1643 - acc: 0.5483\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 2s 1ms/sample - loss: 1.1408 - acc: 0.5567\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 2s 1ms/sample - loss: 1.0929 - acc: 0.5817\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 1ms/sample - loss: 1.1102 - acc: 0.5567\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 1ms/sample - loss: 1.1170 - acc: 0.5383\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 856us/sample - loss: 1.0968 - acc: 0.5558\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 837us/sample - loss: 1.1019 - acc: 0.5367\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 861us/sample - loss: 1.0917 - acc: 0.5425\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 1ms/sample - loss: 1.0686 - acc: 0.5442\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 1ms/sample - loss: 1.0480 - acc: 0.5717\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 1ms/sample - loss: 1.0957 - acc: 0.5292\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 1ms/sample - loss: 1.0645 - acc: 0.5500\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 1ms/sample - loss: 1.0367 - acc: 0.5658\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 1ms/sample - loss: 1.0739 - acc: 0.5417\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 1ms/sample - loss: 1.0288 - acc: 0.5567\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 803us/sample - loss: 1.0290 - acc: 0.5617\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 1s 808us/sample - loss: 1.0372 - acc: 0.5392\n",
      "Train on 1200 samples\n",
      "1200/1200 [==============================] - 2s 1ms/sample - loss: 1.0230 - acc: 0.5408\n",
      "CPU times: user 1min 39s, sys: 20.6 s, total: 1min 59s\n",
      "Wall time: 59.2 s\n"
     ]
    }
   ],
   "source": [
    "%time trainInBatch(clfNN,1200,X_train,encoded_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011807433737732787\n"
     ]
    }
   ],
   "source": [
    "result1=accuracy(clfNN,X_train,encoded_y_train,1000)\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 52.3 GiB for an array with shape (51764, 135538) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-2d9adb1817ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclfNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoded_y_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/DL/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    830\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m   def predict(self,\n",
      "\u001b[0;32m~/DL/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, model, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steps'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    696\u001b[0m     return test_loop(\n\u001b[1;32m    697\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DL/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2487\u001b[0m       \u001b[0mconverted_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_expected_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m         \u001b[0mconverted_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_scipy_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverted_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m       \u001b[0mx_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DL/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_convert_scipy_sparse_tensor\u001b[0;34m(value, expected_input)\u001b[0m\n\u001b[1;32m   3233\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3234\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dense_tensor_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3235\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3236\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3237\u001b[0m       \u001b[0msparse_coo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocoo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DL/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m             \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Output array must be C or F contiguous'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DL/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 52.3 GiB for an array with shape (51764, 135538) and data type int64"
     ]
    }
   ],
   "source": [
    "result2=clfNN.evaluate(X_train,encoded_y_train,batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51764, 135538) (51764, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,encoded_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "1000/1000 [==============================] - 1s 786us/sample - loss: 1.1300 - acc: 0.5410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f12fa3470f0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=600\n",
    "start=7000\n",
    "stop=8000\n",
    "clfNN.fit(X_train[start:stop][:],encoded_y_train[start:stop][:])\n",
    "                 \n",
    "                 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
