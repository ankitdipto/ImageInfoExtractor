{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras import Sequential,layers\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath2='/home/ankit/Documents/ML/ImageInfoExtractor/datasets/Digital_Music_5.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_json(filePath2,lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3EBHHCZO6V2A4</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Amaranth \"music fan\"</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>It's hard to believe \"Memory of Trees\" came ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>Enya's last great album</td>\n",
       "      <td>1158019200</td>\n",
       "      <td>09 12, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AZPWAXJG9OJXV</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>bethtexas</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>A clasically-styled and introverted album, Mem...</td>\n",
       "      <td>5</td>\n",
       "      <td>Enya at her most elegant</td>\n",
       "      <td>991526400</td>\n",
       "      <td>06 3, 2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A38IRL0X2T4DPF</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>bob turnley</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>I never thought Enya would reach the sublime h...</td>\n",
       "      <td>5</td>\n",
       "      <td>The best so far</td>\n",
       "      <td>1058140800</td>\n",
       "      <td>07 14, 2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A22IK3I6U76GX0</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Calle</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>This is the third review of an irish album I w...</td>\n",
       "      <td>5</td>\n",
       "      <td>Ireland produces good music.</td>\n",
       "      <td>957312000</td>\n",
       "      <td>05 3, 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1AISPOIIHTHXX</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Cloud \"...\"</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Enya, despite being a successful recording art...</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5; music to dream to</td>\n",
       "      <td>1200528000</td>\n",
       "      <td>01 17, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64701</th>\n",
       "      <td>A1PQ1PESSO8CMO</td>\n",
       "      <td>B00KILDVEI</td>\n",
       "      <td>Ginger Christmas</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I like the reggae sound a lot in this song. I ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Cool song</td>\n",
       "      <td>1403568000</td>\n",
       "      <td>06 24, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64702</th>\n",
       "      <td>A120RH58WVY4W6</td>\n",
       "      <td>B00KILDVEI</td>\n",
       "      <td>Kelly Dunwell \"avid reader\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I first heard this on Sirius and had to have i...</td>\n",
       "      <td>5</td>\n",
       "      <td>Great Song</td>\n",
       "      <td>1404864000</td>\n",
       "      <td>07 9, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64703</th>\n",
       "      <td>A19VJ2IQLO50G0</td>\n",
       "      <td>B00KILDVEI</td>\n",
       "      <td>melinda</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>I absolutely love this song, it downloaded fin...</td>\n",
       "      <td>5</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1405209600</td>\n",
       "      <td>07 13, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64704</th>\n",
       "      <td>AUDSM2CTLLW1Q</td>\n",
       "      <td>B00KILDVEI</td>\n",
       "      <td>Patrick L. Randall</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Reggae, island beats aren't really my cup of t...</td>\n",
       "      <td>3</td>\n",
       "      <td>Well-crafted song</td>\n",
       "      <td>1404864000</td>\n",
       "      <td>07 9, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64705</th>\n",
       "      <td>A1GN8UJIZLCA59</td>\n",
       "      <td>B00KILDVEI</td>\n",
       "      <td>P Magnum</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>Magic! is a Canadian band that incorporates re...</td>\n",
       "      <td>1</td>\n",
       "      <td>Souless Reggae</td>\n",
       "      <td>1405641600</td>\n",
       "      <td>07 18, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64706 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           reviewerID        asin                 reviewerName helpful  \\\n",
       "0      A3EBHHCZO6V2A4  5555991584         Amaranth \"music fan\"  [3, 3]   \n",
       "1       AZPWAXJG9OJXV  5555991584                    bethtexas  [0, 0]   \n",
       "2      A38IRL0X2T4DPF  5555991584                  bob turnley  [2, 2]   \n",
       "3      A22IK3I6U76GX0  5555991584                        Calle  [1, 1]   \n",
       "4      A1AISPOIIHTHXX  5555991584                  Cloud \"...\"  [1, 1]   \n",
       "...               ...         ...                          ...     ...   \n",
       "64701  A1PQ1PESSO8CMO  B00KILDVEI             Ginger Christmas  [0, 0]   \n",
       "64702  A120RH58WVY4W6  B00KILDVEI  Kelly Dunwell \"avid reader\"  [0, 0]   \n",
       "64703  A19VJ2IQLO50G0  B00KILDVEI                      melinda  [0, 1]   \n",
       "64704   AUDSM2CTLLW1Q  B00KILDVEI           Patrick L. Randall  [0, 0]   \n",
       "64705  A1GN8UJIZLCA59  B00KILDVEI                     P Magnum  [1, 2]   \n",
       "\n",
       "                                              reviewText  overall  \\\n",
       "0      It's hard to believe \"Memory of Trees\" came ou...        5   \n",
       "1      A clasically-styled and introverted album, Mem...        5   \n",
       "2      I never thought Enya would reach the sublime h...        5   \n",
       "3      This is the third review of an irish album I w...        5   \n",
       "4      Enya, despite being a successful recording art...        4   \n",
       "...                                                  ...      ...   \n",
       "64701  I like the reggae sound a lot in this song. I ...        4   \n",
       "64702  I first heard this on Sirius and had to have i...        5   \n",
       "64703  I absolutely love this song, it downloaded fin...        5   \n",
       "64704  Reggae, island beats aren't really my cup of t...        3   \n",
       "64705  Magic! is a Canadian band that incorporates re...        1   \n",
       "\n",
       "                            summary  unixReviewTime   reviewTime  \n",
       "0           Enya's last great album      1158019200  09 12, 2006  \n",
       "1          Enya at her most elegant       991526400   06 3, 2001  \n",
       "2                   The best so far      1058140800  07 14, 2003  \n",
       "3      Ireland produces good music.       957312000   05 3, 2000  \n",
       "4            4.5; music to dream to      1200528000  01 17, 2008  \n",
       "...                             ...             ...          ...  \n",
       "64701                     Cool song      1403568000  06 24, 2014  \n",
       "64702                    Great Song      1404864000   07 9, 2014  \n",
       "64703                    Five Stars      1405209600  07 13, 2014  \n",
       "64704             Well-crafted song      1404864000   07 9, 2014  \n",
       "64705                Souless Reggae      1405641600  07 18, 2014  \n",
       "\n",
       "[64706 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdf=df[[\"reviewText\",\"summary\",\"overall\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's hard to believe \"Memory of Trees\" came ou...</td>\n",
       "      <td>Enya's last great album</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A clasically-styled and introverted album, Mem...</td>\n",
       "      <td>Enya at her most elegant</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I never thought Enya would reach the sublime h...</td>\n",
       "      <td>The best so far</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is the third review of an irish album I w...</td>\n",
       "      <td>Ireland produces good music.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Enya, despite being a successful recording art...</td>\n",
       "      <td>4.5; music to dream to</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  \\\n",
       "0  It's hard to believe \"Memory of Trees\" came ou...   \n",
       "1  A clasically-styled and introverted album, Mem...   \n",
       "2  I never thought Enya would reach the sublime h...   \n",
       "3  This is the third review of an irish album I w...   \n",
       "4  Enya, despite being a successful recording art...   \n",
       "\n",
       "                        summary  overall  \n",
       "0       Enya's last great album        5  \n",
       "1      Enya at her most elegant        5  \n",
       "2               The best so far        5  \n",
       "3  Ireland produces good music.        5  \n",
       "4        4.5; music to dream to        4  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=subdf['reviewText'].values\n",
    "y=subdf['overall'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 136858 unique tokens.\n",
      "(64706, 100)\n",
      "(64706, 6)\n"
     ]
    }
   ],
   "source": [
    "MAX_NUM_WORDS=1000\n",
    "MAX_SEQUENCE_LENGTH=100\n",
    "MAX_NUM_WORDS = 1000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "labels = to_categorical(subdf['overall'].values)\n",
    "print(data.shape)\n",
    "print(labels.shape)                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data))\n",
    "print(type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train, sentences_test, y_train, y_test=\\\n",
    "train_test_split(data,labels,test_size=0.20,random_state=62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#vectorizer=CountVectorizer(min_df=0, lowercase=False)\n",
    "#vectorizer.fit(sentences_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(sentences_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train=vectorizer.transform(sentences_train)\n",
    "#X_test=vectorizer.transform(sentences_test)\n",
    "#y_train=y_train.reshape(-1,1)\n",
    "#y_test=y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_train.shape,y_train.shape)\n",
    "#print(vectorizer.vocabulary_)\n",
    "#print(len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"one_hot_encoder=OneHotEncoder(sparse=False)\n",
    "one_hot_encoder.fit(y_train)\n",
    "encoded_y_train=one_hot_encoder.transform(y_train)\n",
    "encoded_y_test=one_hot_encoder.transform(y_test)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(encoded_y_train)\n",
    "#print(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clfBase=LogisticRegression(max_iter=1400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clfBase.fit(X_train,encoded_y_train)\n",
    "#scoreBase=clfBase.score(X_test,encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(scoreBase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ankit/DL/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "clfNN=Sequential()\n",
    "clfNN.add(layers.Dense(7,input_dim=sentences_train.shape[1],activation='sigmoid'))\n",
    "clfNN.add(layers.Dense(8,activation='sigmoid'))\n",
    "clfNN.add(layers.Dense(6,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfNN.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 7)                 707       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 64        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 54        \n",
      "=================================================================\n",
      "Total params: 825\n",
      "Trainable params: 825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clfNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"!rm -r ./logs/fit/*\n",
    "logDirPath='logs/fit/'+datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboardCallback=tf.keras.callbacks.TensorBoard(log_dir=logDirPath,histogram_freq=1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51764, 6)\n",
      "(51764, 100)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(sentences_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ankit/DL/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 51764 samples\n",
      "51764/51764 [==============================] - 2s 42us/sample - loss: 1.2672 - acc: 0.5050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f026308a860>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfNN.fit(sentences_train,y_train)\n",
    "          \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.548509 and Loss: 1.1971317\n",
      "Testing  Accuracy: 0.555324 and Loss: 1.1909520\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy=clfNN.evaluate(sentences_train,y_train,verbose=False)\n",
    "print(\"Training Accuracy: {:.6f} and Loss: {:.7f}\".format(accuracy,loss))\n",
    "loss,accuracy=clfNN.evaluate(sentences_test,y_test,verbose=False)\n",
    "print(\"Testing  Accuracy: {:.6f} and Loss: {:.7f}\".format(accuracy,loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X_train))\n",
    "tf.sparse.to_dense(X_train)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 37)           37000     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3700)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 22206     \n",
      "=================================================================\n",
      "Total params: 59,206\n",
      "Trainable params: 59,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=MAX_NUM_WORDS,output_dim=37,input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "#model.add(layers.GlobalAveragePooling1D())\n",
    "model.add(layers.Dense(6, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(type(model.layers[0].output))\n",
    "print(type(model.layers[1].output))\n",
    "print(type(model.layers[2].output))\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 51764 samples\n",
      "51764/51764 [==============================] - 1s 19us/sample - loss: 1.3717 - acc: 0.5331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0262e6eb70>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences_train,y_train,batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def trainInBatch(model,batch_size,X_train,y_train):\n",
    "    print(\"No. of training examples: \",X_train.shape[0])\n",
    "    numOfBatches=X_train.shape[0]//batch_size\n",
    "    for idx in range(numOfBatches):\n",
    "        start=idx*batch_size\n",
    "        stop=min((idx+1)*batch_size,X_train.shape[0])\n",
    "        model.fit(X_train[start:stop][:],y_train[start:stop])\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model,X,y,batch_size):\n",
    "    y_pred=np.zeros(y.shape)\n",
    "    numOfBatches=X.shape[0]//batch_size\n",
    "    cnt=0\n",
    "    for idx in range(numOfBatches):\n",
    "        start=idx*batch_size\n",
    "        stop=min((idx+1)*batch_size,X.shape[0])\n",
    "        y_pred[start:stop][:]=model.predict(X[start:stop][:])\n",
    "    return (y_pred==y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time trainInBatch(clfNN,1200,X_train,encoded_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result1=accuracy(clfNN,X_train,encoded_y_train,1000)\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2=clfNN.evaluate(X_train,encoded_y_train,batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape,encoded_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=600\n",
    "start=7000\n",
    "stop=8000\n",
    "clfNN.fit(X_train[start:stop][:],encoded_y_train[start:stop][:])\n",
    "                 \n",
    "                 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
